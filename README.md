# ğŸ•·ï¸ Web Scraping Premium (Python)

Scraper profissional para coleta robusta de dados: rotaÃ§Ã£o de User-Agent, retry inteligente, paginaÃ§Ã£o avanÃ§ada, exportaÃ§Ã£o limpa e logs detalhados.

---

## ğŸ“Œ VisÃ£o Geral

Este projeto oferece um scraper de nÃ­vel profissional, capaz de extrair dados de sites reais de modo:

- Estruturado
- Resiliente
- EscalÃ¡vel
- Seguro
- ConfiÃ¡vel

Diferente de scrapers simples, este foi pensado para suportar:

- AlternÃ¢ncia de headers
- Diversos erros HTTP (timeouts/5xx/429)
- PaginaÃ§Ã£o automÃ¡tica
- HTML inconsistente
- MÃºltiplos formatos de saÃ­da
- Logs completos

Ã‰ o tipo de soluÃ§Ã£o entregue por freelancers em Upwork, Workana e 99Freelas, normalmente para Ã¡reas como BI, Pricing, Marketing, SEO, Auditoria, Financeiro ou InteligÃªncia Competitiva.

---

## ğŸš€ Principais Recursos

### 1ï¸âƒ£ RequisiÃ§Ãµes HTTP realistas (User-Agent + Headers)

- SimulaÃ§Ã£o de navegador real
- Headers completos e variados
- RotaÃ§Ã£o dinÃ¢mica de User-Agents
- Sleep aleatÃ³rio para evitar bloqueios
- Reduz drasticamente cÃ³digos 429, 503 e banimentos

---

### 2ï¸âƒ£ Retry com Backoff Exponencial

- Gerenciamento automÃ¡tico para erros como:
  - Timeout
  - ConexÃ£o perdida
  - 429 â€œToo Many Requestsâ€
  - 5xx
- Tentativas automÃ¡ticas com delays progressivos

---

### 3ï¸âƒ£ Parsing Resiliente (BeautifulSoup)

- ExtraÃ§Ãµes robustas (nome, preÃ§o, categoria, descriÃ§Ã£o, disponibilidade, rating)
- Limpeza e padronizaÃ§Ã£o integradas

---

### 4ï¸âƒ£ PaginaÃ§Ã£o Inteligente

- Detecta e percorre botÃ£o â€œprÃ³xima pÃ¡ginaâ€ automaticamente
- Previne loops infinitos
- Registra pÃ¡ginas visitadas e coleta incremental
- Navega atÃ© o final sem intervenÃ§Ã£o manual

---

### 5ï¸âƒ£ VÃ¡rios formatos de saÃ­da

- CSV (padrÃ£o)
- Excel (.xlsx)
- JSON

Exemplo de arquivo de saÃ­da:

```
output/
â””â”€â”€ scraped_YYYYMMDD_HHMMSS.csv
```

---

### 6ï¸âƒ£ Logging AvanÃ§ado

- GeraÃ§Ã£o de logs detalhados em `output/scraper.log`:
  - Status das requisiÃ§Ãµes
  - Tentativas e retries
  - Tempo total do scraping
  - Quantidade de pÃ¡ginas e registros coletados
- Facilita auditoria e debugging

---

### 7ï¸âƒ£ CLI Completa

Principais comandos:

```bash
# Scraping padrÃ£o
python scraper.py

# Customizar URL target
python scraper.py --url https://books.toscrape.com/catalogue/page-1.html

# Limitar pÃ¡ginas
python scraper.py --max-pages 5

# Customizar diretÃ³rio de saÃ­da
python scraper.py --output-dir ./dados

# Gerar JSON e Excel
python scraper.py --json --excel

# Ativar logs detalhados
python scraper.py -v
```

---

## ğŸ§  Estrutura do Projeto

```
webscraping-premium/
â”œâ”€â”€ scraper.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ output/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ screenshot-raw.png
â”‚   â”œâ”€â”€ screenshot-clean.png
â”‚   â””â”€â”€ demo.gif
â””â”€â”€ src/
    â”œâ”€â”€ fetcher.py      # RequisiÃ§Ãµes HTTP
    â”œâ”€â”€ parser.py       # Parsing e extraÃ§Ã£o
    â”œâ”€â”€ paginator.py    # LÃ³gica de paginaÃ§Ã£o
    â”œâ”€â”€ exporter.py     # CSV / Excel / JSON
    â””â”€â”€ utils.py        # FunÃ§Ãµes auxiliares
```

---

## ğŸ“„ Site de DemonstraÃ§Ã£o

O scraper utiliza o site Books to Scrape (usado para fins educacionais/demos), extraindo:

- TÃ­tulo do livro
- PreÃ§o
- Rating
- Disponibilidade
- Link direto
- Categoria

---

## ğŸ“ Exemplo de SaÃ­da

Confira `sample_output.csv` com cerca de 60 registros extraÃ­dos automaticamente.

---

## ğŸ”– Tecnologias

- Python
- Requests
- BeautifulSoup
- Pandas
- Lxml
- OpenPyXL
- Logging avanÃ§ado

---

## ğŸ“„ LicenÃ§a

Livre para uso e adaptaÃ§Ã£o comercial.